/* Generated by RuntimeBrowser
   Image: /System/Library/PrivateFrameworks/TextGenerationInference.framework/TextGenerationInference
 */

@interface TGITextGenerationInferenceRunner : NSObject <TGITextGenerationInferenceRunner> {
    bool  _canceled;
    struct shared_ptr<TGITextGenerationInferenceDecodingPolicy> { 
        struct TGITextGenerationInferenceDecodingPolicy {} *__ptr_; 
        struct __shared_weak_count {} *__cntrl_; 
    }  _decodingPolicy;
    NSUUID * _executionUUID;
    struct shared_ptr<TGITextGenerationInferenceModelInterface> { 
        struct TGITextGenerationInferenceModelInterface {} *__ptr_; 
        struct __shared_weak_count {} *__cntrl_; 
    }  _model;
    TGTextGenerationOperation * _operation;
    TGITextGenerationInferenceSession * _session;
    bool  _shouldDoCacheLookUp;
    NSObject<OS_dispatch_queue> * _workQueue;
}

@property (getter=isCanceled) bool canceled;
@property (readonly, copy) NSString *debugDescription; /* unknown property attribute: ? */
@property (readonly) struct shared_ptr<TGITextGenerationInferenceDecodingPolicy> { struct TGITextGenerationInferenceDecodingPolicy {} *x1; struct __shared_weak_count {} *x2; } decodingPolicy;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSUUID *executionUUID;
@property (readonly) unsigned long long hash;
@property struct shared_ptr<TGITextGenerationInferenceModelInterface> { struct TGITextGenerationInferenceModelInterface {} *x1; struct __shared_weak_count {} *x2; } model;
@property (readonly, copy) TGTextGenerationOperation *operation;
@property (readonly) TGITextGenerationInferenceSession *session;
@property bool shouldDoCacheLookUp;
@property (readonly) Class superclass;
@property (readonly) NSObject<OS_dispatch_queue> *workQueue;

- (id).cxx_construct;
- (void).cxx_destruct;
- (void)cancel;
- (struct shared_ptr<TGITextGenerationInferenceDecodingPolicy> { struct TGITextGenerationInferenceDecodingPolicy {} *x1; struct __shared_weak_count {} *x2; })decodingPolicy;
- (id)executionUUID;
- (id)initWithQueue:(id)arg1 executionUUID:(id)arg2 operation:(id)arg3 session:(id)arg4;
- (bool)isCanceled;
- (struct shared_ptr<TGITextGenerationInferenceModelInterface> { struct TGITextGenerationInferenceModelInterface {} *x1; struct __shared_weak_count {} *x2; })model;
- (id)operation;
- (void)run;
- (struct TGITextGenerationInferenceWordFragment { int x1; struct basic_string<char, std::char_traits<char>, std::allocator<char>> { struct __compressed_pair<std::basic_string<char>::__rep, std::allocator<char>> { struct __rep { union { struct __short { BOOL x_1_5_1[23]; unsigned char x_1_5_2[0]; unsigned int x_1_5_3 : 7; unsigned int x_1_5_4 : 1; } x_1_4_1; struct __long { char *x_2_5_1; unsigned long long x_2_5_2; unsigned int x_2_5_3 : 63; unsigned int x_2_5_4 : 1; } x_1_4_2; struct __raw { unsigned long long x_3_5_1[3]; } x_1_4_3; } x_1_3_1; } x_1_2_1; } x_2_1_1; } x2; })runIncrementalInferenceWithTokenIDs:(const void*)arg1;
- (id)session;
- (void)setCanceled:(bool)arg1;
- (void)setModel:(struct shared_ptr<TGITextGenerationInferenceModelInterface> { struct TGITextGenerationInferenceModelInterface {} *x1; struct __shared_weak_count {} *x2; })arg1;
- (void)setShouldDoCacheLookUp:(bool)arg1;
- (bool)shouldDoCacheLookUp;
- (id)workQueue;

@end
